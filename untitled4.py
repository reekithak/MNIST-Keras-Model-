# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FUSFZh8T-MnXkKC1tHH9qtxWEWBVpS6A
"""

from keras.datasets import mnist

(X_train,y_train),(X_test,y_test)=mnist.load_data()



print(list(map(lambda x : x.shape,[X_train,y_train,X_test,y_test])))

import cv2
import numpy as np
import matplotlib.pyplot as plt

for i in range(0,3):
  n=np.random.randint(0,len(X_train))
  img=X_train[n]
  win_name="rand sample"+ str(i)
  cv2.imshow(win_name,img)
  cv2.waitKey(0)
cv2.destroyAllWindows()

for i in range(0,3):
  n=np.random.randint(0,len(X_train))
  a=np.random.randint(330,333)
  plt.subplot(a)
  plt.imshow(X_train[n],cmap=plt.get_cmap('gray'))

im_rows = X_train[0].shape[0]
im_col = X_train[0].shape[0]

#reshape
X_train=X_train.reshape(X_train.shape[0],im_rows,im_col,1);X_test=X_test.reshape(X_test.shape[0],im_rows,im_col,1)

ip_shape=(im_rows,im_col,1)
print(ip_shape)

X_train=X_train.astype('float32')
X_test=X_test.astype('float32')

#normalise
X_train/=255
X_test/=255
print(X_train.shape)

#hot-encoding
from keras.utils import np_utils
y_train=np_utils.to_categorical(y_train)
y_test=np_utils.to_categorical(y_test)
n_case=y_train.shape[1]
print("No : of classes = {}".format(y_train.shape[1]))

import tensorflow as tf
from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D ,MaxPooling2D

from tensorflow.keras import Sequential
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import SGD

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=(28,28,1)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(n_case, activation='softmax'))
print(model.summary())

optimizer=SGD(0.01)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
print(model.summary())

batch_size=1
epochs=2
history = model.fit(X_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(X_test, y_test))
score = model.evaluate(X_test, y_test, verbose=0)



print(score)



#loss plot 

history_dict = history.history
loss_values=history_dict['loss']
val_loss_values=history['val_loss']
epochs = range(1,len(loss_values)+1)

line1=plt.plot(epochs,val_loss_values,labels='Validation/Test Loss')
line2=plt.plot(epochs,loss_values,label='Training Loss')
plt.setp(line1,linewidth=2.0,marker='+',markersize=10.0)
plt.setp(line2,linewidth=2.0,marker='+',markersize=10.0)
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.grid(True)
plt.legend()
plt.show()

#Accuracy plot

history_dict = history.history
acc_values=history_dict['acc']
val_loss_values=history['val_acc']
epochs = range(1,len(loss_values)+1)

line1=plt.plot(epochs,val_acc_values,labels='Validation/Test Accuracy')
line2=plt.plot(epochs,acc_values,label='Training Accuracy')
plt.setp(line1,linewidth=2.0,marker='+',markersize=10.0)
plt.setp(line2,linewidth=2.0,marker='+',markersize=10.0)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid(True)
plt.legend()
plt.show()

#save our model
model.save("loc")

#loading

from keras.models import load_model
clasifier= load_model("loc")

#visualizing the model 
from keras.utils import plot_model

plot_model("loc")